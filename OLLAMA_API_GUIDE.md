# Ollama API ä½¿ç”¨æŒ‡å—

## ğŸš€ OllamaæœåŠ¡çŠ¶æ€

- **æœåŠ¡åœ°å€**: `http://localhost:11434`
- **å·²å®‰è£…æ¨¡å‹**: `deepseek-coder-v2:latest`
- **æ¨¡å‹å¤§å°**: 8.9GB
- **å‚æ•°è§„æ¨¡**: 15.7B
- **é‡åŒ–çº§åˆ«**: Q4_0

## ğŸ“¡ APIç«¯ç‚¹æ¦‚è§ˆ

### 1. æ¨¡å‹ç®¡ç†API

#### åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
```bash
curl http://localhost:11434/api/tags
```

#### æ‹‰å–æ¨¡å‹
```bash
curl -X POST http://localhost:11434/api/pull \
  -H "Content-Type: application/json" \
  -d '{"name": "deepseek-coder-v2"}'
```

#### åˆ é™¤æ¨¡å‹
```bash
curl -X DELETE http://localhost:11434/api/delete \
  -H "Content-Type: application/json" \
  -d '{"name": "deepseek-coder-v2"}'
```

### 2. èŠå¤©API

#### åŸºç¡€èŠå¤©è¯·æ±‚
```bash
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder-v2",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
      }
    ],
    "stream": false
  }'
```

#### æµå¼èŠå¤©è¯·æ±‚
```bash
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder-v2",
    "messages": [
      {
        "role": "user",
        "content": "å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—"
      }
    ],
    "stream": true
  }'
```

### 3. ç”ŸæˆAPI

#### å•æ¬¡ç”Ÿæˆ
```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder-v2",
    "prompt": "å†™ä¸€ä¸ªJavaScriptå‡½æ•°æ¥åè½¬å­—ç¬¦ä¸²",
    "stream": false
  }'
```

## ğŸ Pythonå®¢æˆ·ç«¯ç¤ºä¾‹

### åŸºç¡€Pythonå®¢æˆ·ç«¯
```python
import requests
import json

class OllamaClient:
    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
    
    def list_models(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        response = requests.get(f"{self.base_url}/api/tags")
        return response.json()
    
    def chat(self, model, messages, stream=False):
        """å‘é€èŠå¤©è¯·æ±‚"""
        payload = {
            "model": model,
            "messages": messages,
            "stream": stream
        }
        response = requests.post(
            f"{self.base_url}/api/chat",
            headers={"Content-Type": "application/json"},
            json=payload
        )
        return response.json()
    
    def generate(self, model, prompt, stream=False):
        """å‘é€ç”Ÿæˆè¯·æ±‚"""
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": stream
        }
        response = requests.post(
            f"{self.base_url}/api/generate",
            headers={"Content-Type": "application/json"},
            json=payload
        )
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = OllamaClient()

# åˆ—å‡ºæ¨¡å‹
models = client.list_models()
print("å¯ç”¨æ¨¡å‹:", models)

# èŠå¤©ç¤ºä¾‹
response = client.chat(
    model="deepseek-coder-v2",
    messages=[
        {"role": "user", "content": "å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—é˜¶ä¹˜"}
    ]
)
print("å›å¤:", response["message"]["content"])
```

### æµå¼å¤„ç†ç¤ºä¾‹
```python
import requests
import json

def stream_chat(model, messages):
    """æµå¼èŠå¤©å¤„ç†"""
    payload = {
        "model": model,
        "messages": messages,
        "stream": True
    }
    
    response = requests.post(
        "http://localhost:11434/api/chat",
        headers={"Content-Type": "application/json"},
        json=payload,
        stream=True
    )
    
    for line in response.iter_lines():
        if line:
            data = json.loads(line.decode('utf-8'))
            if 'message' in data:
                content = data['message']['content']
                print(content, end='', flush=True)
            if data.get('done', False):
                break

# ä½¿ç”¨ç¤ºä¾‹
stream_chat(
    "deepseek-coder-v2",
    [{"role": "user", "content": "è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’"}]
)
```

## ğŸ”§ é«˜çº§é…ç½®

### æ¨¡å‹å‚æ•°é…ç½®
```bash
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder-v2",
    "messages": [
      {
        "role": "user",
        "content": "å†™ä¸€ä¸ªæ’åºç®—æ³•"
      }
    ],
    "options": {
      "temperature": 0.7,
      "top_p": 0.9,
      "top_k": 40,
      "num_predict": 1000,
      "stop": ["\n\n", "```"]
    }
  }'
```

### å‚æ•°è¯´æ˜
- **temperature**: æ§åˆ¶éšæœºæ€§ (0.0-1.0)
- **top_p**: æ ¸é‡‡æ ·å‚æ•° (0.0-1.0)
- **top_k**: ä¿ç•™å‰kä¸ªtoken
- **num_predict**: æœ€å¤§ç”Ÿæˆtokenæ•°
- **stop**: åœæ­¢ç”Ÿæˆçš„æ ‡è®°

## ğŸ› ï¸ åœ¨CodeWiseé¡¹ç›®ä¸­çš„é›†æˆ

### åˆ›å»ºOllamaæœåŠ¡æ¨¡å—
```python
# rag/ollama_service.py
import requests
import json
from typing import List, Dict, Optional
from loguru import logger

class OllamaService:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "deepseek-coder-v2"
    
    def health_check(self) -> bool:
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"OllamaæœåŠ¡æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def generate_code_explanation(self, code: str, context: str = "") -> str:
        """ç”Ÿæˆä»£ç è§£é‡Š"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹ä»£ç å¹¶ç»™å‡ºè¯¦ç»†è§£é‡Šï¼š

ä»£ç ï¼š
```python
{code}
```

ä¸Šä¸‹æ–‡ï¼š{context}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œåˆ†æï¼š
1. ä»£ç åŠŸèƒ½
2. å®ç°é€»è¾‘
3. å…³é”®éƒ¨åˆ†è¯´æ˜
4. å¯èƒ½çš„æ”¹è¿›å»ºè®®
"""
        
        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                headers={"Content-Type": "application/json"},
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 2000
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()["response"]
            else:
                logger.error(f"Ollama APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return "ä»£ç åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OllamaæœåŠ¡å¤±è´¥: {e}")
            return "ä»£ç åˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
    
    def answer_code_question(self, question: str, code_context: str = "") -> str:
        """å›ç­”ä»£ç ç›¸å…³é—®é¢˜"""
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æä»£ç ç»“æ„ã€è§£é‡Šå®ç°é€»è¾‘ã€æä¾›æ”¹è¿›å»ºè®®ã€‚"
            },
            {
                "role": "user",
                "content": f"é—®é¢˜ï¼š{question}\n\nç›¸å…³ä»£ç ï¼š{code_context}"
            }
        ]
        
        try:
            response = requests.post(
                f"{self.base_url}/api/chat",
                headers={"Content-Type": "application/json"},
                json={
                    "model": self.model,
                    "messages": messages,
                    "stream": False,
                    "options": {
                        "temperature": 0.4,
                        "num_predict": 1500
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()["message"]["content"]
            else:
                logger.error(f"OllamaèŠå¤©APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                return "é—®ç­”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
                
        except Exception as e:
            logger.error(f"è°ƒç”¨OllamaèŠå¤©æœåŠ¡å¤±è´¥: {e}")
            return "é—®ç­”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    ollama = OllamaService()
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if ollama.health_check():
        print("âœ… OllamaæœåŠ¡æ­£å¸¸è¿è¡Œ")
        
        # æµ‹è¯•ä»£ç è§£é‡Š
        test_code = """
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
"""
        explanation = ollama.generate_code_explanation(test_code)
        print("ä»£ç è§£é‡Š:", explanation)
    else:
        print("âŒ OllamaæœåŠ¡ä¸å¯ç”¨")
```

## ğŸš€ å¿«é€Ÿæµ‹è¯•

### æµ‹è¯•æœåŠ¡çŠ¶æ€
```bash
# æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
curl http://localhost:11434/api/tags

# æµ‹è¯•ç®€å•å¯¹è¯
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-coder-v2",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ]
  }'
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æœåŠ¡å¯åŠ¨**: ç¡®ä¿OllamaæœåŠ¡åœ¨åå°è¿è¡Œ
2. **æ¨¡å‹åŠ è½½**: é¦–æ¬¡ä½¿ç”¨æ¨¡å‹æ—¶å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´åŠ è½½
3. **å†…å­˜ä½¿ç”¨**: å¤§æ¨¡å‹ä¼šå ç”¨è¾ƒå¤šå†…å­˜
4. **ç½‘ç»œè®¿é—®**: é»˜è®¤åªç›‘å¬localhostï¼Œå¦‚éœ€å¤–éƒ¨è®¿é—®éœ€è¦é…ç½®
5. **é”™è¯¯å¤„ç†**: å»ºè®®åœ¨ä»£ç ä¸­æ·»åŠ é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

## ğŸ”— ç›¸å…³èµ„æº

- [Ollamaå®˜æ–¹æ–‡æ¡£](https://ollama.ai/docs)
- [Ollama APIå‚è€ƒ](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [æ¨¡å‹åº“](https://ollama.ai/library)
